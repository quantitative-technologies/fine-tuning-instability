# fine-tuning-instability


## Fine-Tuning Instability for Large Language Models


This repository contains the implementation for the `AdamWL2SP` optimizer, as 
described in this [blog post](https://quantitative-technologies.github.io/fine-tuning-instability/).
`AdamWL2SP` is Adaptive Momentum (Adam) with $L^2-\mathrm{SP}$ regularization with
decoupled weight decay.

